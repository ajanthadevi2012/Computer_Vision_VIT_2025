{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjW5B7QxaAPb"
      },
      "source": [
        "# Computer Vision for Beginners: Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDtjwKKJaAPc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49DVnbz5aAPd"
      },
      "outputs": [],
      "source": [
        "def display(img, cmap = None):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(img, cmap = cmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59T_nigaAPd"
      },
      "source": [
        "# Blurring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA7EkMdgaAPd"
      },
      "source": [
        "The goal of blurring is to perform noise reduction. But we have to pay extra care here. If we apply edge detection algorithms to the images with high resolution, we'll get too many detected outcomes that we aren't interested in.\n",
        "\n",
        "![img](https://github.com/jjone36/vision_4_beginners/blob/master/images/part2_img1.png?raw=true)\n",
        "\n",
        "On the contrary, if we blur the images too much, we'll lose the data. Therefore we need to find an adequate amount of blurring we're going to apply without losing desirable edges.\n",
        "\n",
        "There are several techniques used to achieve blurring effects but we're going to talk about the four major ones used in OpenCV: **Averaging blurring, Gaussian blurring, median blurring** and **bilateral filtering**. All four techniques have a common basic principle, which is applying convolutional operations to the image with a filter (kernel). The values of the applying filters are different between the four blurring methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u2seAuwaAPe"
      },
      "source": [
        "***Average blurring*** is taking the average of all the pixel values under the given kernel area and replace the value at the center. For example, suppose we have a kernel with the size of 5X5. We calculate the average of the convoluted outcome and put that result to the center of the given area.\n",
        "\n",
        "![img](https://github.com/jjone36/vision_4_beginners/blob/master/images/part2_img2.png?raw=true)\n",
        "\n",
        "Then what will it be like if we increase the size of the kernel? As the size of filters gets bigger, the pixel values will be normalized more. Therefore we can expect the image to get blurred the more. Let's check out the result with the code as follows. (For comparison, I'll keep attaching the original image to the result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXuAxMRDaAPe"
      },
      "outputs": [],
      "source": [
        "img_text = cv2.imread('/content/text.jpg')\n",
        "img_text  = cv2.cvtColor(img_text, cv2.COLOR_BGR2RGB)\n",
        "display(img_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STrJEZq8aAPe"
      },
      "outputs": [],
      "source": [
        "img_copy1 = img_text.copy()\n",
        "kernels = [5,11,17]\n",
        "fig , axs = plt.subplots(nrows = 1, ncols = 3, figsize = (20,20))\n",
        "for ind, s in enumerate(kernels):\n",
        "    img_blurred = cv2.blur(img_copy1, ksize = (s,s))\n",
        "    ax = axs[ind]\n",
        "    ax.imshow(img_blurred)\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYt9eyKEaAPf"
      },
      "outputs": [],
      "source": [
        "img_0 = cv2.blur(img_copy1, ksize = (7,7))\n",
        "img_1 = cv2.GaussianBlur(img_copy1, ksize = (7,7), sigmaX = 0)\n",
        "img_2 = cv2.medianBlur(img_copy1, 7)\n",
        "img_3 = cv2.bilateralFilter(img_copy1, 7, sigmaSpace = 75, sigmaColor = 75)\n",
        "\n",
        "images = [img_0, img_1, img_2, img_3]\n",
        "fig, axs = plt.subplots(nrows = 1, ncols = 4, figsize = (20,20))\n",
        "for ind, p in enumerate(images):\n",
        "    ax = axs[ind]\n",
        "    ax.imshow(p)\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1MKxjdfaAPf"
      },
      "source": [
        "# Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI6Oan-AaAPf"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/gradation.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdMUcaqeaAPf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpjnOQi0aAPf"
      },
      "source": [
        "# Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kA7u5RaAPf"
      },
      "source": [
        "***Laplacian operation*** uses the second derivatives of x and y. The mathematical expression is shown below.\n",
        "![img](https://github.com/jjone36/vision_4_beginners/blob/master/images/part2_img5.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-RVWZkmaAPg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQWsuezdaAPg"
      },
      "source": [
        "# Morphological transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_aYs3DLaAPg"
      },
      "source": [
        "***Erosion*** is the technique for shrinking figures and it's usually processed in a grayscale. The shape of filters can be a rectangle, an ellipse, and a cross shape. By applying a filter we remove any 0 values under the given area.\n",
        "\n",
        "![img](https://github.com/jjone36/vision_4_beginners/blob/master/images/part2_img6.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXI_YWQPaAPg"
      },
      "source": [
        "is the mixed version of erosion and dilation. Opening performs erosion first and then dilation is performed on the result from the erosion while closing performs dilation first and the erosion.\n",
        "\n",
        "![img](https://github.com/jjone36/vision_4_beginners/blob/master/images/part2_img7.png?raw=true)\n",
        "\n",
        "As you can see the picture above, closing is useful to detect the overall contour of a figure and opening is suitable to detect subpatterns. We can implement these operators with the function `cv2.morphologyEx()` shown below. The parameter `op` indicates which type of operator we're going to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiKKlsKiaAPg"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/content/simpson.jpg')\n",
        "img = cv2.bitwise_not(img)\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlAwMKNHaAPg"
      },
      "outputs": [],
      "source": [
        "kernel_0 = np.ones((9,9), np.uint8)\n",
        "kernel_1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
        "kernel_2 = cv2.getStructuringElement(cv2.MORPH_CROSS, (9,9))\n",
        "kernels = [kernel_0, kernel_1, kernel_2]\n",
        "\n",
        "fig , axs = plt.subplots(nrows = 1, ncols = 3, figsize = (20,20))\n",
        "for  i in range(3):\n",
        "    img_copy = img.copy()\n",
        "    img_copy = cv2.erode(img_copy, kernels[i], iterations = 3)\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(img_copy)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNH1WUAbaAPg"
      },
      "outputs": [],
      "source": [
        "kernel= np.ones((9,9), np.uint8)\n",
        "img_dilate = cv2.dilate(img, kernel, iterations = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6p1EFAraAPg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(img_dilate)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEiPGmOkaAPh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}